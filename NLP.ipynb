{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUuyLVDZ4s8r",
        "colab_type": "text"
      },
      "source": [
        "## ЗАДАНИЕ ДЛЯ ПРОГРАММИРУЮЩИХ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwJ5Q6w2IFHA",
        "colab_type": "text"
      },
      "source": [
        "**Ссылка**, на источник текста"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64uxt-07IEec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_URL = \"http://az.lib.ru/n/nekrasow_n_a/text_1840_pevitza.shtml\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwrBkeLnHuA1",
        "colab_type": "text"
      },
      "source": [
        "Устанавливаем библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5Fr5swwYfz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbxMKqhPH1Dk",
        "colab_type": "text"
      },
      "source": [
        "Создаём объект морфологического анализатора `RNNMorph`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24zMUhvi99AV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from rnnmorph.predictor import RNNMorphPredictor\n",
        "predictor = RNNMorphPredictor(language=\"ru\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59q1L9p0H9K9",
        "colab_type": "text"
      },
      "source": [
        "Скачиваем текст, по которому будет дано задание, с помощью `urllib`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uW0fw_h-Pft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "opener = urllib.request.URLopener({})\n",
        "resource = opener.open(DATA_URL)\n",
        "raw_text = resource.read().decode(resource.headers.get_content_charset()) #Текс с html тегами"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZiLHQNSITAt",
        "colab_type": "text"
      },
      "source": [
        "Удаляем из текста HTML-теги с помощью простого регулярного выражения (используем их, так как структура документа и небольшие ошибки с извлечением текста нас мало волнуют)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We4LkyUMPfuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "clean_pattern = re.compile(\"<.*?>\")\n",
        "\n",
        "def clean_html(raw_html: str):\n",
        "  clean_text = re.sub(clean_pattern, \" \", raw_html)\n",
        "  return clean_text\n",
        "\n",
        "cleaned_text = clean_html(raw_text)#Текс без html тегов"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14fYYb5hIpnY",
        "colab_type": "text"
      },
      "source": [
        "С помощью библиотеки [NLTK](https://nltk.org/) разбиваем текст на предложения и токены."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRNu7jPvN6G_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "de679b62-9f92-4fe2-9eec-d4ae95578a6f"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "tokenized_sentences = [word_tokenize(sentence) for sentence in sent_tokenize(cleaned_text)]\n",
        "\"A total of %d 'sentences'\" % len(tokenized_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"A total of 914 'sentences'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRU4KEBAIyYT",
        "colab_type": "text"
      },
      "source": [
        "## Задание 1\n",
        "С помощью метода `str.isalpha` из стандартной библиотеки Python модифицируйте нижеследующий код так, чтобы в predictions остались только буквенные токены."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U5HH2CDPVUM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "b5f458ad-c4ad-4486-de22-7d4d7b525290"
      },
      "source": [
        "from tqdm import tqdm\n",
        "predictions = [[pred.normal_form for pred in sent if pred.normal_form.isalpha()] \n",
        "               for sent in tqdm(predictor.predict_sentences(sentences=tokenized_sentences), \"sentences\")]\n",
        "predictions[-12:-11] #Сейчас видно, что токены типа \"точка\", \"запятая\", \"дефис\" и тд пока присутствуют в предложениях. От них нужно избавиться\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "sentences: 100%|██████████| 914/914 [00:00<00:00, 90212.82it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['nbsp', 'nbsp', 'секунда']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHGDhxhNJtTz",
        "colab_type": "text"
      },
      "source": [
        "Проверьте себя. Должны получиться следующие значения:\n",
        "\n",
        "*   Предложений: 576\n",
        "*   Токенов: 8639"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwK_qRbw6sac",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a01e4957-d352-4958-9256-916ae446dd9c"
      },
      "source": [
        "len(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "914"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5jL4sWyKUnO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64af201c-bbef-4b05-f0a1-fa3c59417738"
      },
      "source": [
        "non_uniq_tokens = [word for sentence in predictions for word in sentence]\n",
        "len(non_uniq_tokens) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12710"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg2e-1hAKiT3",
        "colab_type": "text"
      },
      "source": [
        "Для продолжения работы над заданием числа должны совпасть!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mci9Nd5hKuJP",
        "colab_type": "text"
      },
      "source": [
        "## Задание 2\n",
        "\n",
        "Используя `non_uniq_tokens`, стоп-слова для русского языка из библиотеки nltk (`nltk.corpus.stopwords`) и `nltk.FreqDist`, вычислите, **какую долю среди 100 самых частотных** токенов в произведении занимают токены, **не относящиеся** к стоп словам. \n",
        "\n",
        "**Например**, если среди 100 самых частотных слов встречается 25 слов, входящих в стоп лист, значит не входят в стоп лист 75 слов, и их доля составит 0.75. \n",
        "\n",
        "**Не бойтесь использовать документацию NLTK и тьюториалы.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHbtLqkLKfZC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "574b38fb-5890-40f5-a44d-7df14dccaa24"
      },
      "source": [
        "import nltk\n",
        "from nltk import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "STOPWORDS = set(stopwords.words(\"russian\"))\n",
        "stopwords.words(\"russian\")[:5] #Пример стоп слов\n",
        "\n",
        "\n",
        "f_dist = FreqDist(non_uniq_tokens)\n",
        "\n",
        "most_commons_my = [word for word, counts in f_dist.most_common(200)]\n",
        "\n",
        "filtered_tokens = [t for t in most_commons_my\n",
        "                   if t not in STOPWORDS]\n",
        "\n",
        "len(filtered_tokens) / 200"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.665"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezdbB95YwtSl",
        "colab_type": "text"
      },
      "source": [
        "Проверьте себя: должно получиться 0.49"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HChyAdk2Ovx1",
        "colab_type": "text"
      },
      "source": [
        "## Задание 3\n",
        "Вычислите, сколько токенов встречается в тексте **строго больше** 50 раз."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihNZK-LubxmD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77f6e5d4-e0c1-4587-881a-c07f169a6f81"
      },
      "source": [
        "\n",
        "most_commons_my = [word for word, counts in f_dist.most_common(100) if counts > 100]\n",
        "len(most_commons_my)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6HZ2w3yxJEh",
        "colab_type": "text"
      },
      "source": [
        "Проверьте себя: должно получиться значение 22\n"
      ]
    }
  ]
}